{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import gc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b38e35648745259f4546e1a0935c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 1000\n",
    "min_nodes = 4\n",
    "max_nodes = 20\n",
    "min_edges = 4\n",
    "\n",
    "data_list = []\n",
    "\n",
    "for i in tqdm(range(n_samples)):\n",
    "    n_nodes = random.randint(min_nodes, max_nodes)\n",
    "    x_features = torch.randn((n_nodes, 3))\n",
    "    x_mask = torch.zeros((n_nodes, 1))\n",
    "    x = torch.cat([x_features, x_mask], dim=1)\n",
    "        \n",
    "#     max_edges = math.factorial(n_nodes)\n",
    "    n_edges = random.randint(min_edges, n_nodes * 2)\n",
    "    edge_index = torch.randint(0, n_nodes - 1, (2, n_edges)).long()\n",
    "    \n",
    "    \n",
    "    edge_attr = torch.cat([torch.randn((n_edges, 1)), torch.zeros((n_edges, 2))], dim=1)\n",
    "\n",
    "    data = Data(\n",
    "        x=x,\n",
    "        edge_index=edge_index,\n",
    "        edge_attr=edge_attr\n",
    "    )\n",
    "    \n",
    "    data_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0].x.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list[0].edge_attr.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"device\": 0,\n",
    "    \"batch_size\": 256,\n",
    "    \"epochs\": 100,\n",
    "    \"lr\": 0.001,\n",
    "    \"decay\": 0,\n",
    "    \"num_layer\": 5,\n",
    "    \"emb_dim\": 300,\n",
    "    \"dropout_ratio\": 0,\n",
    "    \"mask_rate\": 0.15,\n",
    "    \"mask_edge\": 1,\n",
    "    \"JK\": \"last\",\n",
    "    \"output_model_file\": '',\n",
    "    \"gnn_type\": \"gat\",\n",
    "    \"seed\": 0, \n",
    "    \"num_workers\": 8,\n",
    "    \"csize\": 3,\n",
    "    \"mode\": \"skipgram\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONFIG[\"num_layer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_func(x, batch, mode = \"sum\"):\n",
    "    if mode == \"sum\":\n",
    "        return global_add_pool(x, batch)\n",
    "    elif mode == \"mean\":\n",
    "        return global_mean_pool(x, batch)\n",
    "    elif mode == \"max\":\n",
    "        return global_max_pool(x, batch)\n",
    "\n",
    "def cycle_index(num, shift):\n",
    "    arr = torch.arange(num) + shift\n",
    "    arr[-shift:] = torch.arange(shift)\n",
    "    return arr\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train(CONFIG, model_substruct, model_context, loader, optimizer_substruct, optimizer_context, device):\n",
    "    model_substruct.train()\n",
    "    model_context.train()\n",
    "\n",
    "    balanced_loss_accum = 0\n",
    "    acc_accum = 0\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        # creating substructure representation\n",
    "        substruct_rep = model_substruct(batch.x_substruct, batch.edge_index_substruct, batch.edge_attr_substruct)[batch.center_substruct_idx]\n",
    "        \n",
    "        ### creating context representations\n",
    "        overlapped_node_rep = model_context(batch.x_context, batch.edge_index_context, batch.edge_attr_context)[batch.overlap_context_substruct_idx]\n",
    "\n",
    "        #Contexts are represented by \n",
    "        if CONFIG[\"mode\"] == \"cbow\":\n",
    "            # positive context representation\n",
    "            context_rep = pool_func(overlapped_node_rep, batch.batch_overlapped_context, mode = CONFIG[\"context_pooling\"])\n",
    "            # negative contexts are obtained by shifting the indicies of context embeddings\n",
    "            neg_context_rep = torch.cat([context_rep[cycle_index(len(context_rep), i+1)] for i in range(CONFIG[\"neg_samples\"])], dim = 0)\n",
    "            \n",
    "            pred_pos = torch.sum(substruct_rep * context_rep, dim = 1)\n",
    "            pred_neg = torch.sum(substruct_rep.repeat((CONFIG[\"neg_samples\"], 1))*neg_context_rep, dim = 1)\n",
    "\n",
    "        elif CONFIG[\"mode\"] == \"skipgram\":\n",
    "\n",
    "            expanded_substruct_rep = torch.cat([substruct_rep[i].repeat((batch.overlapped_context_size[i],1)) for i in range(len(substruct_rep))], dim = 0)\n",
    "            pred_pos = torch.sum(expanded_substruct_rep * overlapped_node_rep, dim = 1)\n",
    "\n",
    "            #shift indices of substructures to create negative examples\n",
    "            shifted_expanded_substruct_rep = []\n",
    "            for i in range(CONFIG[\"neg_samples\"]):\n",
    "                shifted_substruct_rep = substruct_rep[cycle_index(len(substruct_rep), i+1)]\n",
    "                shifted_expanded_substruct_rep.append(torch.cat([shifted_substruct_rep[i].repeat((batch.overlapped_context_size[i],1)) for i in range(len(shifted_substruct_rep))], dim = 0))\n",
    "\n",
    "            shifted_expanded_substruct_rep = torch.cat(shifted_expanded_substruct_rep, dim = 0)\n",
    "            pred_neg = torch.sum(shifted_expanded_substruct_rep * overlapped_node_rep.repeat((CONFIG[\"neg_samples\"], 1)), dim = 1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode!\")\n",
    "\n",
    "        loss_pos = criterion(pred_pos.double(), torch.ones(len(pred_pos)).to(pred_pos.device).double())\n",
    "        loss_neg = criterion(pred_neg.double(), torch.zeros(len(pred_neg)).to(pred_neg.device).double())\n",
    "\n",
    "        \n",
    "        optimizer_substruct.zero_grad()\n",
    "        optimizer_context.zero_grad()\n",
    "\n",
    "        loss = loss_pos + CONFIG[\"neg_samples\"]*loss_neg\n",
    "        loss.backward()\n",
    "        #To write: optimizer\n",
    "        optimizer_substruct.step()\n",
    "        optimizer_context.step()\n",
    "\n",
    "        balanced_loss_accum += float(loss_pos.detach().cpu().item() + loss_neg.detach().cpu().item())\n",
    "        acc_accum += 0.5* (float(torch.sum(pred_pos > 0).detach().cpu().item())/len(pred_pos) + float(torch.sum(pred_neg < 0).detach().cpu().item())/len(pred_neg))\n",
    "\n",
    "    return balanced_loss_accum/step, acc_accum/step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipgram\n",
      "num layer: 5 l1: 4 l2: 7\n",
      "====epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|                                                                                                                                      | 0/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 71\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m====epoch \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch))\n\u001b[0;32m---> 71\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_substruct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_substruct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mprint\u001b[39m(train_loss, train_acc)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m CONFIG[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_model_file\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[0;32mIn [7], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(CONFIG, model_substruct, model_context, loader, optimizer_substruct, optimizer_context, device)\u001b[0m\n\u001b[1;32m     20\u001b[0m balanced_loss_accum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     21\u001b[0m acc_accum \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m     24\u001b[0m     batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# creating substructure representation\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/any-domain-pretrain-gnns/venv/lib/python3.8/site-packages/tqdm/std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1192\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1195\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1196\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1197\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1198\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/any-domain-pretrain-gnns/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    680\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 681\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    685\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/PycharmProjects/any-domain-pretrain-gnns/venv/lib/python3.8/site-packages/torch/utils/data/dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    720\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 721\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    722\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    723\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/PycharmProjects/any-domain-pretrain-gnns/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/PycharmProjects/any-domain-pretrain-gnns/venv/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch\u001b[39m(\u001b[38;5;28mself\u001b[39m, possibly_batched_index):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/PycharmProjects/any-domain-pretrain-gnns/chem/mydataset.py:170\u001b[0m, in \u001b[0;36mMyDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, (\u001b[38;5;28mint\u001b[39m, np\u001b[38;5;241m.\u001b[39minteger))\n\u001b[1;32m    166\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, Tensor) \u001b[38;5;129;01mand\u001b[39;00m idx\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    167\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(idx, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(idx))):\n\u001b[1;32m    169\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices()[idx])\n\u001b[0;32m--> 170\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/PycharmProjects/any-domain-pretrain-gnns/chem/util.py:96\u001b[0m, in \u001b[0;36mExtractSubstructureContextPair.__call__\u001b[0;34m(self, data, root_idx)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m root_idx \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     root_idx \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(\u001b[38;5;28mrange\u001b[39m(num_atoms), \u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m---> 96\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_data_obj_to_nx_simple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# same ordering as input data obj\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Get k-hop subgraph rooted at specified atom idx\u001b[39;00m\n\u001b[1;32m     99\u001b[0m substruct_node_idxes \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39msingle_source_shortest_path_length(G,\n\u001b[1;32m    100\u001b[0m                                                              root_idx,\n\u001b[1;32m    101\u001b[0m                                                              \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk)\u001b[38;5;241m.\u001b[39mkeys()\n",
      "File \u001b[0;32m~/PycharmProjects/any-domain-pretrain-gnns/chem/loader.py:161\u001b[0m, in \u001b[0;36mgraph_data_obj_to_nx_simple\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    159\u001b[0m num_atoms \u001b[38;5;241m=\u001b[39m atom_features\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_atoms):\n\u001b[0;32m--> 161\u001b[0m     atomic_num_idx, chirality_tag_idx \u001b[38;5;241m=\u001b[39m atom_features[i]\n\u001b[1;32m    162\u001b[0m     G\u001b[38;5;241m.\u001b[39madd_node(i, atom_num_idx\u001b[38;5;241m=\u001b[39matomic_num_idx, chirality_tag_idx\u001b[38;5;241m=\u001b[39mchirality_tag_idx)\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "from chem.dataloader import DataLoaderMasking, DataLoaderSubstructContext  # , DataListLoader\n",
    "from chem.mydataset import MyDataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from chem.model import GNN, GNN_graphpred\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from chem.util import MaskNode, ExtractSubstructureContextPair\n",
    "\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "import timeit\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "device = torch.device(\"cuda:\" + str(CONFIG[\"device\"])) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "\n",
    "l1 = CONFIG[\"num_layer\"] - 1\n",
    "l2 = l1 + CONFIG[\"csize\"]\n",
    "\n",
    "print(CONFIG[\"mode\"])\n",
    "print(\"num layer: %d l1: %d l2: %d\" %(CONFIG[\"num_layer\"], l1, l2))\n",
    "\n",
    "#set up dataset and transform function.\n",
    "dataset = MyDataset(data_list, transform = ExtractSubstructureContextPair(CONFIG[\"num_layer\"], l1, l2))\n",
    "loader = DataLoaderSubstructContext(dataset, \n",
    "                                    batch_size=CONFIG[\"batch_size\"], \n",
    "                                    shuffle=True, \n",
    "                                    num_workers=0)\n",
    "\n",
    "#set up models, one for pre-training and one for context embeddings\n",
    "model_substruct = GNN(CONFIG[\"num_layer\"], \n",
    "                      CONFIG[\"emb_dim\"], \n",
    "                      x_input_dim=data_list[0].x.shape[1], \n",
    "                      edge_attr_input_dim=data_list[0].edge_attr.shape[1], \n",
    "                      JK = CONFIG[\"JK\"], \n",
    "                      drop_ratio = CONFIG[\"dropout_ratio\"], \n",
    "                      gnn_type = CONFIG[\"gnn_type\"]).to(device)\n",
    "\n",
    "model_context = GNN(int(l2 - l1), \n",
    "                    CONFIG[\"emb_dim\"], \n",
    "                    JK = CONFIG[\"JK\"], \n",
    "                    x_input_dim=data_list[0].x.shape[1], \n",
    "                    edge_attr_input_dim=data_list[0].edge_attr.shape[1], \n",
    "                    drop_ratio = CONFIG[\"dropout_ratio\"], \n",
    "                    gnn_type = CONFIG[\"gnn_type\"]).to(device)\n",
    "\n",
    "#set up optimizer for the two GNNs\n",
    "optimizer_substruct = optim.Adam(model_substruct.parameters(), lr=CONFIG[\"lr\"], weight_decay=CONFIG[\"decay\"])\n",
    "optimizer_context = optim.Adam(model_context.parameters(), lr=CONFIG[\"lr\"], weight_decay=CONFIG[\"decay\"])\n",
    "\n",
    "for epoch in range(1, CONFIG[\"epochs\"] + 1):\n",
    "    print(\"====epoch \" + str(epoch))\n",
    "\n",
    "    train_loss, train_acc = train(CONFIG, model_substruct, model_context, loader, optimizer_substruct, optimizer_context, device)\n",
    "    print(train_loss, train_acc)\n",
    "\n",
    "if not CONFIG[\"output_model_file\"] == \"\":\n",
    "    torch.save(model_substruct.state_dict(), CONFIG[\"output_model_file\"] + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'chem.batch' from '/Users/user/PycharmProjects/any-domain-pretrain-gnns/chem/batch.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "from chem import model, util, batch\n",
    "\n",
    "importlib.reload(model)\n",
    "importlib.reload(util)\n",
    "importlib.reload(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
